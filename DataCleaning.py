# -*- coding: utf-8 -*-
"""Untitled6.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JI9Z7fV7BOYKAQzK5h7nmtoodXvLGc_z
"""

import pandas as pd
import numpy as np
pd.set_option('display.max_rows', None)
pd.set_option('display.max_columns', None)

samples = pd.read_csv('resultphyschem[1].csv',index_col=0)
station = pd.read_csv('station[1].csv',index_col=0)

joineddata = samples.merge(station, how = 'left', on = 'MonitoringLocationIdentifier')
print(joineddata.columns)
columns_to_keep = [
    'MonitoringLocationIdentifier',
    'HUCEightDigitCode',
    'LatitudeMeasure',
    'LongitudeMeasure',
    'CharacteristicName',
    'ResultMeasure/MeasureUnitCode',
    'ResultMeasureValue',
]

joineddatanew = joineddata[columns_to_keep]
joineddatanew['ResultMeasureValue'] = pd.to_numeric(joineddatanew['ResultMeasureValue'], errors='coerce')
joineddata['DetectionQuantitationLimitMeasure/MeasureValue'] = pd.to_numeric(joineddata['DetectionQuantitationLimitMeasure/MeasureValue'], errors='coerce')

mask_A = joineddatanew['ResultMeasureValue'].isna() & joineddata['DetectionQuantitationLimitMeasure/MeasureValue'].notna()
joineddatanew.loc[mask_A, 'ResultMeasureValue'] = joineddata.loc[mask_A, 'DetectionQuantitationLimitMeasure/MeasureValue'] / 2
joineddatanew.loc[mask_A, "ResultMeasure/MeasureUnitCode"] = joineddata.loc[mask_A, "DetectionQuantitationLimitMeasure/MeasureUnitCode"]

# Converting all values to ug/L
mask_mg = (joineddatanew["ResultMeasure/MeasureUnitCode"] == "mg/L") | (joineddatanew["ResultMeasure/MeasureUnitCode"] == "mg/kg")
joineddatanew.loc[mask_mg, "ResultMeasureValue"] *= 1000
joineddatanew = joineddatanew.drop("ResultMeasure/MeasureUnitCode", axis=1)

# Dropping all NA Values
joineddatanew = joineddatanew.dropna(subset=[
    "LatitudeMeasure",
    "LongitudeMeasure",
    "ResultMeasureValue",
    "HUCEightDigitCode"
])

# Extracting Ground Truth Labels

# Final Touches
joineddatayes = joineddatanew[joineddatanew["CharacteristicName"] == "Arsenic"]
joineddatanew = joineddatanew[joineddatanew['CharacteristicName']=='Boron']
joineddatanew.drop(columns=['CharacteristicName'])
cols = ['LatitudeMeasure','LongitudeMeasure',"ResultMeasureValue"]
ground_truth = joineddatayes[cols]
joineddatanew.rename(columns ={'ResultMeasureValue':'BoronValue'}, inplace = True)

ground_truth.shape

usgs = pd.read_csv('fullphyschem (1).csv', index_col=0)
cols_keep = ['Location_Identifier', 'Location_HUCEightDigitCode','Location_HUCTwelveDigitCode','Location_Latitude','Location_Longitude','Result_ResultDetectionCondition','Result_Measure','Result_MeasureUnit','DetectionLimit_MeasureA','DetectionLimit_MeasureB','DetectionLimit_MeasureUnitA','DetectionLimit_MeasureUnitB']
usgs = usgs[cols_keep
]

maskA1 = usgs['Result_Measure'].isna() & usgs['DetectionLimit_MeasureA'].notna()
usgs.loc[maskA1, 'Result_Measure'] = usgs.loc[maskA1, 'DetectionLimit_MeasureA'] / 2
usgs.loc[maskA1, "Result_MeasureUnit"] = usgs.loc[maskA1, "DetectionLimit_MeasureUnitA"]

maskB1 = usgs['Result_Measure'].isna() & usgs['DetectionLimit_MeasureA'].isna() & usgs['DetectionLimit_MeasureB'].notna()
usgs.loc[maskB1, 'Result_Measure'] = usgs.loc[maskB1, 'DetectionLimit_MeasureB'] / 2
usgs.loc[maskB1, "Result_MeasureUnit"] = usgs.loc[maskB1, "DetectionLimit_MeasureUnitB"]

usgs['Is_Detected'] = usgs['Result_Measure'].notna().astype(int)

# Converting all values to ug/L
mask_mg = (usgs["Result_MeasureUnit"] == "ng/L")
usgs.loc[mask_mg, "Result_Measure"] /= 1000
usgs = usgs.drop("Result_MeasureUnit", axis=1)

# Dropping all NA Values
usgs = usgs.dropna(subset=[
    "Location_Latitude",
    "Location_Longitude",
    "Result_Measure",
    "Location_HUCEightDigitCode"
])



usgs.to_csv('usgs.csv',index=False)

usgs.rename(columns ={'Location_HUCEightDigitCode':'HUCEightDigitCode'}, inplace = True)
usgs.rename(columns ={'Location_Latitude':'LatitudeMeasure'}, inplace = True)
usgs.rename(columns ={'Location_Longitude':'LongitudeMeasure'}, inplace = True)
usgs.rename(columns ={'Location_Identifier':'MonitoringLocationIdentifier'}, inplace = True)
# Round coordinates in both DataFrames
# usgs: using column names
usgs.loc[:, 'LatitudeMeasure'] = usgs.loc[:, 'LatitudeMeasure'].round(5)
usgs.loc[:, 'LongitudeMeasure'] = usgs.loc[:, 'LongitudeMeasure'].round(5)

# joineddatanew: using column names
joineddatanew.loc[:, 'LatitudeMeasure'] = joineddatanew.loc[:, 'LatitudeMeasure'].round(5)
joineddatanew.loc[:, 'LongitudeMeasure'] = joineddatanew.loc[:, 'LongitudeMeasure'].round(5)

# ground_truth: using column names
ground_truth.loc[:, 'LatitudeMeasure'] = ground_truth.loc[:, 'LatitudeMeasure'].round(5)
ground_truth.loc[:, 'LongitudeMeasure'] = ground_truth.loc[:, 'LongitudeMeasure'].round(5)

combined = usgs.merge(joineddatanew, on = ['LatitudeMeasure','LongitudeMeasure'], how = 'inner', suffixes = ['_bo','_pfa'])
combined = combined.drop(columns=['CharacteristicName','Result_ResultDetectionCondition','DetectionLimit_MeasureA','DetectionLimit_MeasureB','DetectionLimit_MeasureUnitA','DetectionLimit_MeasureUnitB','Is_Detected','Location_HUCTwelveDigitCode','HUCEightDigitCode_bo','HUCEightDigitCode_pfa','MonitoringLocationIdentifier_bo','MonitoringLocationIdentifier_pfa'])
combined2 = ground_truth.merge(combined, on = ['LatitudeMeasure','LongitudeMeasure'], how = 'inner')
combined2.dropna(subset = ['Result_Measure','BoronValue','ResultMeasureValue'])
combined2.shape

soil = pd.read_csv('soildata.csv')
soil.rename(columns ={'Location_LongitudeStandardized':'LongitudeMeasure'}, inplace = True)
soil.rename(columns ={'Location_LatitudeStandardized':'LatitudeMeasure'}, inplace = True)
soil.columns

soil.loc[:, 'LatitudeMeasure'] = soil.loc[:, 'LatitudeMeasure'].round(5)
soil.loc[:, 'LongitudeMeasure'] = soil.loc[:, 'LongitudeMeasure'].round(5)

from sklearn.neighbors import NearestNeighbors


# --- Convert coordinates to radians (for haversine) ---
soil_coords_rad = np.radians(soil[['LatitudeMeasure', 'LongitudeMeasure']].to_numpy())
chem_coords_rad = np.radians(combined2[['LatitudeMeasure', 'LongitudeMeasure']].to_numpy())

# --- Use NearestNeighbors with haversine distance ---
nn = NearestNeighbors(n_neighbors=1, metric='haversine')
nn.fit(chem_coords_rad)

# --- Find nearest chem site for each soil site ---
distances_rad, indices = nn.kneighbors(soil_coords_rad)
distances_m = distances_rad.flatten() * 6371000  # Convert to meters

# --- Extract matching rows from chem_df ---
matched_chem_df = combined2.iloc[indices.flatten()].reset_index(drop=True)
matched_chem_df = matched_chem_df.add_prefix('chem_')
# --- Add distance to soil_df and combine ---
merged_df = pd.concat([soil.reset_index(drop=True), matched_chem_df], axis=1)
print(merged_df.columns)

merged_df.drop(columns=['Location_HUCEightDigitCode','Is_Detected','Result_Characteristic_Arsenic','Result_Characteristic_Arsenic ion (3+)','Result_Characteristic_Arsenic, Inorganic','year','month','day', 'chem_LatitudeMeasure', 'chem_LongitudeMeasure',],inplace = True)
merged_df.columns

test = merged_df['chem_ResultMeasureValue']
test = np.log1p(test)
merged_df.drop(columns=['chem_ResultMeasureValue'], inplace = True)
test.to_csv('arsenics.csv',index=False)
merged_df.to_csv('trainingfinal.csv',index=False)

print(test.shape)
print(merged_df.shape)
print(merged_df.head())